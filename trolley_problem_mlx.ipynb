{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning Centaur on the Trolley Problem\n",
    "\n",
    "The Centaur model is a large-language model trained to be a foundation model of human cognition ([Binz et al., 2024](https://arxiv.org/pdf/2306.03917)). It is a Llama 3.1 model fine-tuned on various tasks from psychology experiments. The experiments are converted to text format that can be processed by LLMs, which is collected under the [Psych101](https://huggingface.co/datasets/marcelbinz/Psych-101) dataset.\n",
    "\n",
    "In this notebook, we will learn how to fine-tune Centaur on the Trolley Problem task. The Trolley Problem is a classic thought experiment in ethics. It is a moral dilemma that asks whether it is permissible to harm one person to save many others. The task is to decide whether to pull a lever to divert a trolley from a track where it would kill five people to another track where it would kill one person.\n",
    "\n",
    "The experiment can be conducted online using the jsPsych plugin developed by [Younes Strittmatter](https://github.com/younesStrittmatter/sweet-jsPsych/tree/main/plugins/trolley-problem). We will use data from this plugin to fine-tune Centaur on the Trolley Problem task, using the MLX-LM library for Apple Silicon machines.\n",
    "\n",
    "We will follow the LORA tutorial on the [MLX-LM GitHub page](https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/LORA.md), adapting it for the Trolley Problem dataset."
   ],
   "id": "74c296b6d74ed11e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Install MLX-LM\n",
    "First, we need to install the MLX-LM library. To do this, make sure you created a new python environment. Then, simply install mlx-lm using pip:"
   ],
   "id": "46df4520abff76ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "!pip install mlx-lm"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's make sure mlx-lm is successfully installed:",
   "id": "6f2badb1acb9d879"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:44:16.263235Z",
     "start_time": "2025-01-19T16:44:13.167436Z"
    }
   },
   "cell_type": "code",
   "source": "!mlx_lm.generate --prompt \"Hi!\"",
   "id": "226e40834bd43e63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|███████████████████████| 6/6 [00:00<00:00, 167772.16it/s]\r\n",
      "==========\r\n",
      "Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\r\n",
      "==========\r\n",
      "Prompt: 37 tokens, 287.702 tokens-per-sec\r\n",
      "Generation: 26 tokens, 60.600 tokens-per-sec\r\n",
      "Peak memory: 1.856 GB\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download Centaur and convert to MLX-compatible quantized version\n",
    "\n",
    "First we need to use mlx-lm's converter to convert the Centaur model on HuggingFace to MLX-compatible format. We will also quantize the model to make it run faster and easier to fine-tune.\n",
    "\n",
    "Since the 70B model is too large to run on a MacBook Pro or similar Apple machines, we will use the 8B model instead. The 8B model takes around 4.5GB when loaded for inference. Keep in mind that this conversion can take a while, as the model is still quite large. It took around 20 minutes on a base M4 Pro model with 24GB of RAM.\n",
    "\n",
    "_Note_: You only need to do this once!"
   ],
   "id": "3afe8582d0b798d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mlx_lm import convert\n",
    "\n",
    "repo = 'marcelbinz/Llama-3.1-Centaur-8B'\n",
    "convert(repo, quantize=True)"
   ],
   "id": "86b6588b7de6afa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This quantizes the model to 4 bits by default, which should be good for our purposes. The model is saved in the `mlx_model` directory.",
   "id": "f2eeb11c0c8ae158"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating outputs with the converted model\n",
    "\n",
    "Now, let's try generating some text with the converted model to make sure everything is working:"
   ],
   "id": "deca2e1c727dc35f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:58:48.070343Z",
     "start_time": "2025-01-19T16:58:41.466330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "model, tokenizer = load(\"mlx_model\")\n",
    "\n",
    "prompt = \"Hi!\"\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)"
   ],
   "id": "4ec30b4cd5ed6694",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "I'm a 20 year old girl from the UK, and I'm a huge fan of the show! I've been watching it since 2009, and I've been on the forums since 2010. I'm a huge fan of the show, and I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of the show's creator, David Lynch. I'm a huge fan of\n",
      "==========\n",
      "Prompt: 3 tokens, 57.140 tokens-per-sec\n",
      "Generation: 256 tokens, 52.885 tokens-per-sec\n",
      "Peak memory: 9.035 GB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok, not great, but it works! This is a small model fine-tuned on psychology experiments, after all. Now let's try a prompt from the Psych101 dataset:",
   "id": "8312aebeeff677ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T17:04:00.343642Z",
     "start_time": "2025-01-19T17:03:59.647603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"You will be presented with triplets of objects, which will be assigned to the keys H, Y, and E.\\n\" \\\n",
    "  \"In each trial, please indicate which object you think is the odd one out by pressing the corresponding key.\\n\" \\\n",
    "  \"In other words, please choose the object that is the least similar to the other two.\\n\\n\" \\\n",
    "  \"H: plant, Y: chainsaw, and E: periscope. You press <<H>>.\\n\" \\\n",
    "  \"H: tostada, Y: leaf, and E: sail. You press <<H>>.\\n\" \\\n",
    "  \"H: clock, Y: crystal, and E: grate. You press <<Y>>.\\n\" \\\n",
    "  \"H: barbed wire, Y: kale, and E: sweater. You press <<E>>.\\n\" \\\n",
    "  \"H: raccoon, Y: toothbrush, and E: ice. You press <<\"\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True, max_tokens=1)  # Limit the output to 1 token since we only want the response"
   ],
   "id": "5cd61717ff8f495e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Y\n",
      "==========\n",
      "Prompt: 165 tokens, 299.162 tokens-per-sec\n",
      "Generation: 1 tokens, 237.426 tokens-per-sec\n",
      "Peak memory: 9.035 GB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "13e7d047dd30900f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T17:04:09.038993Z",
     "start_time": "2025-01-19T17:04:09.036327Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "b843061fa540b712",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing the Trolley Problem dataset",
   "id": "58a6faa5193c2352"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataset will come from online experiments conducted using the jsPsych plugin developed by [Younes Strittmatter](https://github.com/younesStrittmatter/sweet-jsPsych/tree/main/plugins/trolley-problem). I created an online version of this experiment running on cognition.run, which makes it easy to run online experiments. If you want to run the experiment yourself, go here: https://lcxaoiwo9j.cognition.run/ and follow the instructions.\n",
    "\n",
    "Alternatively, you can install the trolley-problem plugin and run it locally. For more information, see https://github.com/younesStrittmatter/sweet-jsPsych/blob/main/plugins/trolley-problem/examples/example.html.\n",
    "\n",
    "The experiment outputs data in JSON format, which will convert to text prompts for the fine-tuning dataset. Let's load the experiment json file and see what it looks like:"
   ],
   "id": "43362a737d11b884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T20:24:02.533012Z",
     "start_time": "2025-01-19T20:24:02.528083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "data_path = \"data/trolley_problem\"\n",
    "\n",
    "with open(f\"{data_path}/exp.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    for trial in data:\n",
    "        main_count = len(trial['main_track'])\n",
    "        main_count_phrase1 = f'{main_count} people' if main_count > 1 else 'one person'\n",
    "        main_count_phrase2 = f'are {main_count_phrase1}' if main_count > 1 else 'is one person'\n",
    "\n",
    "        side_track = len(trial['side_track'])\n",
    "        side_track_phrase1 = f'{side_track} people' if side_track > 1 else 'one person'\n",
    "        side_track_phrase2 = f'are {side_track} people' if side_track > 1 else 'is one person'\n",
    "\n",
    "        prompt = f\"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track {main_count_phrase2}. There {side_track_phrase2} standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the {main_count_phrase1} on the main track, but it will not hit the {side_track_phrase1} on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the {side_track_phrase1}, and not hit the {main_count_phrase1} on the main track. Respond with N to do nothing, or F to flip the switch.\"\n",
    "\n",
    "        prompt = f\"{prompt}\\n\\nMain track includes the following: {trial['main_track']}. Side track includes the following: {trial['side_track']}. You choose <<\"\n",
    "\n",
    "        completion = f\"{'F' if trial['action'] == 'flip' else 'N'}>>.\"\n",
    "\n",
    "        # print(prompt)\n",
    "        prompts.append({'prompt': prompt, 'completion': completion})\n",
    "    print(prompts)"
   ],
   "id": "40cc6f952484652d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track is one person. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the one person on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the one person on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'male', 'body_type': 'business', 'skin': 'white'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. You choose <<\", 'completion': 'F>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track are 2 people. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the 2 people on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the 2 people on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'female', 'body_type': 'casual', 'skin': 'white'}, {'gender': 'female', 'body_type': 'elderly', 'skin': 'brown'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. You choose <<\", 'completion': 'N>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track are 2 people. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the 2 people on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the 2 people on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'brown'}, {'gender': 'male', 'body_type': 'elderly', 'skin': 'white'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. You choose <<\", 'completion': 'N>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track is one person. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the one person on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the one person on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. Side track includes the following: [{'gender': 'male', 'body_type': 'business', 'skin': 'white'}]. You choose <<\", 'completion': 'F>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track are 2 people. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the 2 people on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the 2 people on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'white'}, {'gender': 'male', 'body_type': 'casual', 'skin': 'white'}]. Side track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'white'}]. You choose <<\", 'completion': 'F>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track are 2 people. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the 2 people on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the 2 people on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'black'}, {'gender': 'male', 'body_type': 'casual', 'skin': 'brown'}]. Side track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'white'}]. You choose <<\", 'completion': 'F>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track is one person. There are 2 people standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the one person on the main track, but it will not hit the 2 people on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the 2 people, and not hit the one person on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'white'}]. Side track includes the following: [{'gender': 'male', 'body_type': 'casual', 'skin': 'white'}, {'gender': 'male', 'body_type': 'casual', 'skin': 'white'}]. You choose <<\", 'completion': 'N>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track are 3 people. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the 3 people on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the 3 people on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}, {'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}, {'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. You choose <<\", 'completion': 'F>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track is one person. There are 3 people standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the one person on the main track, but it will not hit the 3 people on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the 3 people, and not hit the one person on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'brown'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}, {'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}, {'gender': 'female', 'body_type': 'pregnant', 'skin': 'white'}]. You choose <<\", 'completion': 'N>>.'}, {'prompt': \"You are standing by the railroad tracks when you notice an empty boxcar rolling out of control. It is moving so fast that anyone it hits will die. Ahead on the main track is one person. There is one person standing on a side track that doesn't rejoin the main track. If you do nothing, the boxcar will hit the one person on the main track, but it will not hit the one person on the side track. If you flip a switch next to you, it will divert the boxcar to the side track where it will hit the one person, and not hit the one person on the main track. Respond with N to do nothing, or F to flip the switch.\\n\\nMain track includes the following: [{'gender': 'male', 'body_type': 'business', 'skin': 'white'}]. Side track includes the following: [{'gender': 'female', 'body_type': 'pregnant', 'skin': 'black'}]. You choose <<\", 'completion': 'F>>.'}]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's write the prompts to a json-l file that we can use for fine-tuning:",
   "id": "5534538b85daa8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T20:24:05.132660Z",
     "start_time": "2025-01-19T20:24:05.128208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_len = len(prompts)\n",
    "val_len = int(total_len * 0.2) # 20% validation set\n",
    "\n",
    "with open(f\"{data_path}/train.jsonl\", \"w\") as f:\n",
    "    for prompt in prompts[:-val_len]:\n",
    "        json.dump(prompt, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open(f\"{data_path}/val.jsonl\", \"w\") as f:\n",
    "    for prompt in prompts[-val_len:]:\n",
    "        json.dump(prompt, f)\n",
    "        f.write('\\n')"
   ],
   "id": "69d27c7d3514d5c7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompting before fine-tuning\n",
    "\n",
    "First we try the default model of MLX-LM with the first prompt from the dataset:"
   ],
   "id": "e712989c0f23e606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T20:24:39.312002Z",
     "start_time": "2025-01-19T20:24:36.726177Z"
    }
   },
   "cell_type": "code",
   "source": "!mlx_lm.generate --prompt f\"{prompts[0]['prompt']}\"",
   "id": "a8d7155e4f3a959c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|███████████████████████| 6/6 [00:00<00:00, 136770.78it/s]\r\n",
      "==========\r\n",
      "F\r\n",
      "==========\r\n",
      "Prompt: 233 tokens, 680.891 tokens-per-sec\r\n",
      "Generation: 2 tokens, 183.503 tokens-per-sec\r\n",
      "Peak memory: 1.964 GB\r\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's try the same prompt with the converted Centaur model:",
   "id": "931f84c074bcb476"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T20:24:51.593992Z",
     "start_time": "2025-01-19T20:24:50.379278Z"
    }
   },
   "cell_type": "code",
   "source": "response = generate(model, tokenizer, prompt=prompts[0]['prompt'], verbose=True, max_tokens=1)",
   "id": "544cab1fd4e9c0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "N\n",
      "==========\n",
      "Prompt: 198 tokens, 306.849 tokens-per-sec\n",
      "Generation: 1 tokens, 711.174 tokens-per-sec\n",
      "Peak memory: 9.035 GB\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning\n",
    "\n",
    "Now finally we can fine-tune the model on the Trolley Problem dataset. We will use the `mlx_lm.train` command to fine-tune the model. We will use the `train.jsonl` file we created earlier as the training data. We will also use the `--save` flag to save the model after training."
   ],
   "id": "cb5803772676527a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T20:27:41.981643Z",
     "start_time": "2025-01-19T20:27:39.585221Z"
    }
   },
   "cell_type": "code",
   "source": "!mlx_lm.lora --model 'mlx_model' --train --data 'data/trolley_problem' --iters 100",
   "id": "98ab4d58cc7c6521",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n",
      "Loading datasets\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/bin/mlx_lm.lora\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/lora.py\", line 292, in main\r\n",
      "    run(types.SimpleNamespace(**args))\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/lora.py\", line 255, in run\r\n",
      "    train_set, valid_set, test_set = load_dataset(args, tokenizer)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/tuner/datasets.py\", line 204, in load_dataset\r\n",
      "    train, valid, test = load_local_dataset(\r\n",
      "                         ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/tuner/datasets.py\", line 120, in load_local_dataset\r\n",
      "    train, valid, test = [load_subset(data_path / f\"{n}.jsonl\") for n in names]\r\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/tuner/datasets.py\", line 117, in load_subset\r\n",
      "    return create_dataset(data, tokenizer, prompt_feature, completion_feature)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/tuner/datasets.py\", line 96, in create_dataset\r\n",
      "    return CompletionsDataset(data, tokenizer, prompt_feature, completion_feature)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/mlx_lm/tuner/datasets.py\", line 68, in __init__\r\n",
      "    tokenizer.apply_chat_template(\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/transformers/tokenization_utils_base.py\", line 1621, in apply_chat_template\r\n",
      "    chat_template = self.get_chat_template(chat_template, tools)\r\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/imtezcan/.pyenv/versions/3.12.0/envs/centaur-finetuning/lib/python3.12/site-packages/transformers/tokenization_utils_base.py\", line 1789, in get_chat_template\r\n",
      "    raise ValueError(\r\n",
      "ValueError: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating\r\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d17630d30db0d8eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
